"""
ë¶€ë™ì‚° ë°ì´í„° ë¶„ì„ ë° í†µê³„ ë¦¬í¬íŒ… ë„êµ¬
"""

import logging
import pandas as pd
import numpy as np
import xml.etree.ElementTree as ET
from pathlib import Path
import json
from typing import Any, Optional, Dict
from datetime import datetime

from mcp_kr_realestate.server import mcp
from mcp_kr_realestate.utils.ctx_helper import with_context
from mcp.types import TextContent

logger = logging.getLogger("mcp-kr-realestate")

def to_numeric(series: pd.Series) -> pd.Series:
    """Helper function to convert series to numeric, handling commas."""
    return pd.to_numeric(series.astype(str).str.replace(',', ''), errors='coerce')

def analyze_commercial_property_data(df: pd.DataFrame) -> Dict[str, Any]:
    """DataFrameì„ ë°›ì•„ ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° í†µê³„ë¥¼ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if df.empty:
        return {"error": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    def get_col_from_df(df_obj, *names):
        """Helper function to get column by trying multiple names."""
        for name in names:
            if name in df_obj.columns:
                return df_obj[name]
        return pd.Series(dtype='object', index=df_obj.index)

    # --- ë°ì´í„° ì „ì²˜ë¦¬ ---
    df['ê±°ë˜ê¸ˆì•¡_num'] = to_numeric(get_col_from_df(df, 'ê±°ë˜ê¸ˆì•¡', 'dealAmount'))
    df['ì „ìš©ë©´ì _num'] = to_numeric(get_col_from_df(df, 'ì „ìš©ë©´ì ', 'area', 'excluUseAr', 'buildingAr'))
    df['ê±´ì¶•ë…„ë„_num'] = to_numeric(get_col_from_df(df, 'ê±´ì¶•ë…„ë„', 'buildYear'))
    
    df.dropna(subset=['ê±°ë˜ê¸ˆì•¡_num', 'ì „ìš©ë©´ì _num'], inplace=True)
    df = df[df['ì „ìš©ë©´ì _num'] > 0].copy()
    if df.empty:
        return {"error": "ì •ë¦¬ í›„ ìœ íš¨í•œ ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    df['í‰ë‹¹ê°€_ë§Œì›'] = (df['ê±°ë˜ê¸ˆì•¡_num'] / df['ì „ìš©ë©´ì _num']) * 3.305785
    
    current_year = datetime.now().year
    df['ê±´ë¬¼ì—°ë ¹'] = current_year - df['ê±´ì¶•ë…„ë„_num']

    # --- 1. ì¢…í•© í†µê³„ ---
    total_count = len(df)
    total_value = df['ê±°ë˜ê¸ˆì•¡_num'].sum()
    property_type_col = 'ì£¼ìš©ë„' if 'ì£¼ìš©ë„' in df.columns else 'ìœ í˜•'
    type_distribution = df[property_type_col].value_counts().to_dict() if property_type_col in df.columns else {}

    overall_stats = {
        "ì´ ê±°ë˜ ê±´ìˆ˜": total_count,
        "ì´ ê±°ë˜ ëŒ€ê¸ˆ (ë§Œì›)": total_value,
        "ìš©ë„ë³„ ê±°ë˜ ë¶„í¬": type_distribution
    }

    # --- 2. ê°€ê²© ìˆ˜ì¤€ í†µê³„ ---
    price_stats = {
        "ì „ì²´ í‰ê·  ê±°ë˜ê°€ (ë§Œì›)": df['ê±°ë˜ê¸ˆì•¡_num'].mean(),
        "ì „ì²´ ì¤‘ìœ„ ê±°ë˜ê°€ (ë§Œì›)": df['ê±°ë˜ê¸ˆì•¡_num'].median(),
        "ì „ì²´ ìµœê³  ê±°ë˜ê°€ (ë§Œì›)": df['ê±°ë˜ê¸ˆì•¡_num'].max(),
        "ì „ì²´ ìµœì € ê±°ë˜ê°€ (ë§Œì›)": df['ê±°ë˜ê¸ˆì•¡_num'].min()
    }
    if property_type_col in df.columns:
        price_by_type = df.groupby(property_type_col)['ê±°ë˜ê¸ˆì•¡_num'].agg(['mean', 'median', 'max', 'min']).to_dict('index')
        price_stats["ìš©ë„ë³„ ê°€ê²© í†µê³„ (ë§Œì›)"] = price_by_type

    # --- 3. ë‹¨ìœ„ ë©´ì ë‹¹ ê°€ê²© í†µê³„ ---
    price_per_area_stats = {
        "ì „ì²´ í‰ê·  í‰ë‹¹ê°€ (ë§Œì›/í‰)": df['í‰ë‹¹ê°€_ë§Œì›'].mean(),
        "ì „ì²´ ì¤‘ìœ„ í‰ë‹¹ê°€ (ë§Œì›/í‰)": df['í‰ë‹¹ê°€_ë§Œì›'].median()
    }
    if property_type_col in df.columns:
        price_per_area_by_type = df.groupby(property_type_col)['í‰ë‹¹ê°€_ë§Œì›'].agg(['mean', 'median']).to_dict('index')
        price_per_area_stats["ìš©ë„ë³„ í‰ë‹¹ê°€ í†µê³„ (ë§Œì›/í‰)"] = price_per_area_by_type

    # --- 4. ì…ì§€ë³„ í†µê³„ (ë™ë³„) ---
    location_col = 'ë²•ì •ë™' if 'ë²•ì •ë™' in df.columns else 'dong'
    location_stats = {}
    if location_col in df.columns and df[location_col].notna().any():
        location_grouped = df.groupby(location_col)
        location_summary = location_grouped['ê±°ë˜ê¸ˆì•¡_num'].agg(Count='size', Mean='mean', Max='max', Min='min').to_dict('index')
        location_ppa_summary = location_grouped['í‰ë‹¹ê°€_ë§Œì›'].agg(Mean_PPA='mean', Median_PPA='median').to_dict('index')
        for dong, stats in location_summary.items():
            stats.update(location_ppa_summary.get(dong, {}))
        location_stats = location_summary

    # --- 5. ê±´ë¬¼ íŠ¹ì„±ë³„ í†µê³„ ---
    age_bins = [0, 6, 11, 21, np.inf]
    age_labels = ['5ë…„ ì´ë‚´ (ì‹ ì¶•)', '6-10ë…„', '11-20ë…„', '20ë…„ ì´ˆê³¼']
    df['ê±´ë¬¼ì—°ë ¹ëŒ€'] = pd.cut(df['ê±´ë¬¼ì—°ë ¹'], bins=age_bins, labels=age_labels, right=False)
    age_stats = {}
    if not df['ê±´ë¬¼ì—°ë ¹ëŒ€'].isnull().all():
        age_summary = df.groupby('ê±´ë¬¼ì—°ë ¹ëŒ€', observed=True)['ê±°ë˜ê¸ˆì•¡_num'].agg(Count='size', Mean_Price='mean').to_dict('index')
        age_ppa_summary = df.groupby('ê±´ë¬¼ì—°ë ¹ëŒ€', observed=True)['í‰ë‹¹ê°€_ë§Œì›'].agg(Mean_PPA='mean').to_dict()
        for age_group, stats in age_summary.items():
            stats.update(age_ppa_summary.get(age_group, {}))
        age_stats = age_summary

    area_bins = [0, 100, 300, 1000, np.inf]
    area_labels = ['ì†Œí˜• (<100mÂ²)', 'ì¤‘í˜• (100-300mÂ²)', 'ëŒ€í˜• (300-1000mÂ²)', 'ì´ˆëŒ€í˜• (>1000mÂ²)']
    df['ê±´ë¬¼ê·œëª¨'] = pd.cut(df['ì „ìš©ë©´ì _num'], bins=area_bins, labels=area_labels, right=False)
    scale_stats = {}
    if not df['ê±´ë¬¼ê·œëª¨'].isnull().all():
        scale_summary = df.groupby('ê±´ë¬¼ê·œëª¨', observed=True)['ê±°ë˜ê¸ˆì•¡_num'].agg(Count='size', Mean_Price='mean').to_dict('index')
        scale_ppa_summary = df.groupby('ê±´ë¬¼ê·œëª¨', observed=True)['í‰ë‹¹ê°€_ë§Œì›'].agg(Mean_PPA='mean').to_dict()
        for scale_group, stats in scale_summary.items():
            stats.update(scale_ppa_summary.get(scale_group, {}))
        scale_stats = scale_summary

    building_stats = {"ê±´ì¶• ì—°ë ¹ëŒ€ë³„ í†µê³„": age_stats, "ê±´ë¬¼ ê·œëª¨ë³„ í†µê³„ (ì „ìš©ë©´ì  ê¸°ì¤€)": scale_stats}

    return {
        "ì¢…í•© í†µê³„": overall_stats,
        "ê°€ê²© ìˆ˜ì¤€ í†µê³„": price_stats,
        "ë‹¨ìœ„ ë©´ì ë‹¹ ê°€ê²© í†µê³„": price_per_area_stats,
        "ì…ì§€ë³„ í†µê³„ (ë™ë³„)": location_stats,
        "ê±´ë¬¼ íŠ¹ì„±ë³„ í†µê³„": building_stats,
        "ì£¼ì˜ì‚¬í•­": "í‰ë‹¹ê°€ ë° ê±´ë¬¼ ê·œëª¨ëŠ” 'ì „ìš©ë©´ì 'ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìœ¼ë©°, 'ëŒ€ì§€ ì§€ë¶„' ë˜ëŠ” 'ë„ë¡œ ì¡°ê±´' ë°ì´í„°ëŠ” APIì—ì„œ ì œê³µë˜ì§€ ì•Šì•„ ë¶„ì„ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    }

@mcp.tool(
    name="analyze_commercial_property_trade",
    description="""ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚°(ìƒê°€, ì˜¤í”¼ìŠ¤ ë“±) ë§¤ë§¤ ì‹¤ê±°ë˜ ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì›”ê°„ ë¦¬í¬íŠ¸ í˜•ì‹ì˜ í•µì‹¬ í†µê³„ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ ë„êµ¬ëŠ” `get_commercial_property_trade_data`ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ì‘ë™í•©ë‹ˆë‹¤.
ì¢…í•© í†µê³„, ê°€ê²© ìˆ˜ì¤€, í‰ë‹¹ê°€, ì…ì§€ë³„, ê±´ë¬¼ íŠ¹ì„±ë³„ ë“± ë‹¤ê°ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì—¬ ì‹œì¥ ë™í–¥ì„ ê¹Šì´ ìˆê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

- **ì¢…í•© í†µê³„**: ì´ ê±°ë˜ ê±´ìˆ˜, ì´ ê±°ë˜ ëŒ€ê¸ˆ, ìš©ë„ë³„ ê±°ë˜ ë¶„í¬(ìƒê°€/íŒë§¤, ì—…ë¬´ì‹œì„¤ ë“±)ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- **ê°€ê²© ìˆ˜ì¤€ í†µê³„**: ì „ì²´ ë° ìš©ë„ë³„ í‰ê· /ì¤‘ìœ„/ìµœê³ /ìµœì € ê±°ë˜ê°€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- **ë‹¨ìœ„ ë©´ì ë‹¹ ê°€ê²© í†µê³„**: ì „ì²´ ë° ìš©ë„ë³„ í‰ê· /ì¤‘ìœ„ í‰ë‹¹ê°€ë¥¼ ì œê³µí•˜ì—¬ ê°€ì¹˜ ë¹„êµ ê¸°ì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤.
- **ì…ì§€ë³„ í†µê³„**: ë²•ì •ë™ë³„ë¡œ ê±°ë˜ ê±´ìˆ˜ì™€ í‰ê·  ê°€ê²©, í‰ë‹¹ê°€ ë“±ì„ ë¶„ì„í•˜ì—¬ ì§€ì—­ë³„ ì‹œì¥ í¸ì°¨ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- **ê±´ë¬¼ íŠ¹ì„±ë³„ í†µê³„**: ê±´ì¶• ì—°ë ¹ ë° ê±´ë¬¼ ê·œëª¨(ì „ìš©ë©´ì  ê¸°ì¤€)ì— ë”°ë¥¸ ê±°ë˜ ë¶„í¬ì™€ í‰ê·  ê°€ê²©ì„ ì œê³µí•©ë‹ˆë‹¤.

Arguments:
- file_path (str, required): `get_commercial_property_trade_data` ë„êµ¬ë¡œ ìƒì„±ëœ XML ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ.

Returns:
- í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ìƒì„¸í•œ JSON ë¬¸ìì—´.
""",
    tags={"í†µê³„", "ë¶„ì„", "ë¦¬í¬íŠ¸", "ìƒì—…ì—…ë¬´ìš©", "ì‹¤ê±°ë˜ê°€"}
)
def analyze_commercial_property_trade(file_path: str, ctx: Optional[Any] = None) -> TextContent:
    """
    ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° ê±°ë˜ ë°ì´í„° XML íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í†µê³„ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    def call(context):
        try:
            p = Path(file_path)
            if not p.exists():
                return json.dumps({"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}, ensure_ascii=False)

            cache_dir = p.parent.parent / "cache"
            cache_dir.mkdir(parents=True, exist_ok=True)
            cache_path = cache_dir / f"{p.stem}_summary.json"

            # ìºì‹œ í™•ì¸ ë° ì¬ì‚¬ìš© ë¡œì§
            if cache_path.exists():
                source_mtime = p.stat().st_mtime
                cache_mtime = cache_path.stat().st_mtime
                if cache_mtime > source_mtime:
                    logger.info(f"âœ… ìœ íš¨í•œ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {cache_path}")
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return f.read()
            
            logger.info(f"ğŸ”„ ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ë˜ì–´ ìƒˆë¡œìš´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {file_path}")
            tree = ET.parse(p)
            root = tree.getroot()
            
            all_items = root.findall('.//item')
            if not all_items:
                return json.dumps({"error": "XML íŒŒì¼ì— ê±°ë˜ ë°ì´í„° ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)
            
            records = [{child.tag: child.text for child in item} for item in all_items]
            df = pd.DataFrame(records)
            
            summary_data = analyze_commercial_property_data(df)
            
            def default_serializer(o):
                if isinstance(o, (np.integer, np.int64)): return int(o)
                if isinstance(o, (np.floating, np.float64)): return float(o)
                if isinstance(o, (np.ndarray)): return o.tolist()
                if isinstance(o, pd.Timestamp): return o.isoformat()
                raise TypeError(f"Object of type {o.__class__.__name__} is not JSON serializable")

            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=4, default=default_serializer)

            summary_data["summary_cached_path"] = str(cache_path)
            
            return json.dumps(summary_data, ensure_ascii=False, indent=4, default=default_serializer)

        except Exception as e:
            logger.error(f"ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return json.dumps({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, ensure_ascii=False)
            
    result = with_context(ctx, "analyze_commercial_property_trade", call)
    return TextContent(type="text", text=result) 