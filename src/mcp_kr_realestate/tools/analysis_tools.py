"""
ë¶€ë™ì‚° ë°ì´í„° ë¶„ì„ ë° í†µê³„ ë¦¬í¬íŒ… ë„êµ¬
"""

import logging
import pandas as pd
import numpy as np
import xml.etree.ElementTree as ET
from pathlib import Path
import json
from typing import Any, Optional, Dict
from datetime import datetime

from mcp_kr_realestate.server import mcp
from mcp_kr_realestate.utils.ctx_helper import with_context
from mcp.types import TextContent

logger = logging.getLogger("mcp-kr-realestate")

# --- Helper Functions ---
def default_serializer(o):
    """JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ ê¸°ë³¸ serializer. numpy íƒ€ì…ì„ python íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if isinstance(o, (np.integer, np.floating)):
        return o.item()
    if isinstance(o, np.ndarray):
        return o.tolist()
    if isinstance(o, pd.Timestamp):
        return o.isoformat()
    raise TypeError(f"Object of type {o.__class__.__name__} is not JSON serializable")

def to_numeric(series: pd.Series) -> pd.Series:
    """Helper function to convert series to numeric, handling commas."""
    return pd.to_numeric(series.astype(str).str.replace(',', ''), errors='coerce')

def format_unit(value, unit_str, precision=0):
    """Helper function to format a numeric value with a unit string."""
    if pd.isna(value):
        return None
    return f"{value:,.{precision}f} {unit_str}"

def clean_deal_for_display(series):
    """Cleans a deal (pandas Series) for JSON output."""
    deal_dict = series.where(pd.notna(series), None).to_dict()
    
    # Format date
    try:
        deal_dict['dealDate'] = f"{deal_dict.get('dealYear')}-{str(deal_dict.get('dealMonth','')).zfill(2)}-{str(deal_dict.get('dealDay','')).zfill(2)}"
    except (TypeError, ValueError):
        deal_dict['dealDate'] = None

    # Remove intermediate columns
    cols_to_remove = ['ê±°ë˜ê¸ˆì•¡_num', 'ì „ìš©ë©´ì _num', 'ê±´ì¶•ë…„ë„_num', 'í‰ë‹¹ê°€_ë§Œì›', 'ê±´ë¬¼ì—°ë ¹', 'ê±´ë¬¼ì—°ë ¹ëŒ€', 'ê±´ë¬¼ê·œëª¨', 'dealYear', 'dealMonth', 'dealDay']
    for col in cols_to_remove:
        deal_dict.pop(col, None)
        
    return deal_dict

def get_col_from_df(df, *col_names):
    """DataFrameê³¼ ì—¬ëŸ¬ ì»¬ëŸ¼ ì´ë¦„ì„ ë°›ì•„, ì¡´ì¬í•˜ëŠ” ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ Seriesë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    for col in col_names:
        if col in df.columns:
            return df[col]
    # ì–´ë–¤ ì»¬ëŸ¼ë„ ì°¾ì§€ ëª»í•œ ê²½ìš°, Noneìœ¼ë¡œ ì±„ì›Œì§„ Seriesë¥¼ ë°˜í™˜í•˜ì—¬ ì´í›„ ì—°ì‚°ì—ì„œ ì˜¤ë¥˜ê°€ ë‚˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    return pd.Series([None] * len(df), index=df.index, dtype=object)

def get_summary_cache_path(p: Path, property_type: Optional[str] = None, trade_type: Optional[str] = None) -> Path:
    """
    property_type: 'commercial', 'land', 'industrial', 'apartment', 'officetel', 'row_house', 'single_detached', ...
    trade_type: 'trade', 'rent', None
    """
    cache_dir = p.parent.parent / "cache"
    cache_dir.mkdir(parents=True, exist_ok=True)
    # ìƒì—…/í† ì§€/ì°½ê³ (ì‚°ì—…ìš©)ëŠ” ë§¤ë§¤/ì „ì›”ì„¸ êµ¬ë¶„ ì—†ì´ í•˜ë‚˜ì˜ summary
    if property_type in {"commercial", "land", "industrial"}:
        return cache_dir / f"{p.stem}_summary.json"
    # ê·¸ ì™¸ëŠ” ë§¤ë§¤/ì „ì›”ì„¸ë³„ë¡œ ë¶„ë¦¬
    if trade_type:
        return cache_dir / f"{p.stem}_{trade_type}_summary.json"
    return cache_dir / f"{p.stem}_summary.json"

def analyze_commercial_property_data(df: pd.DataFrame) -> Dict[str, Any]:
    """DataFrameì„ ë°›ì•„ ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° í†µê³„ë¥¼ ë¶„ì„í•˜ê³  ì˜ë¬¸ keyì™€ ë‹¨ìœ„ê°€ í¬í•¨ëœ ê°’ìœ¼ë¡œ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if df.empty:
        return {"error": "No data to analyze."}

    # --- ë°ì´í„° ì „ì²˜ë¦¬ ---
    df['ê±°ë˜ê¸ˆì•¡_num'] = to_numeric(get_col_from_df(df, 'ê±°ë˜ê¸ˆì•¡', 'dealAmount'))
    df['ì „ìš©ë©´ì _num'] = to_numeric(get_col_from_df(df, 'ì „ìš©ë©´ì ', 'area', 'excluUseAr', 'buildingAr'))
    df['ê±´ì¶•ë…„ë„_num'] = to_numeric(get_col_from_df(df, 'ê±´ì¶•ë…„ë„', 'buildYear'))
    
    df.dropna(subset=['ê±°ë˜ê¸ˆì•¡_num', 'ì „ìš©ë©´ì _num'], inplace=True)
    df = df[df['ì „ìš©ë©´ì _num'] > 0].copy()
    if df.empty:
        return {"error": "No valid transaction data after cleaning."}

    df['í‰ë‹¹ê°€_ë§Œì›'] = (df['ê±°ë˜ê¸ˆì•¡_num'] / df['ì „ìš©ë©´ì _num']) * 3.305785
    
    current_year = datetime.now().year
    df['ê±´ë¬¼ì—°ë ¹'] = current_year - df['ê±´ì¶•ë…„ë„_num']

    # --- Formatting helpers ---
    def krw_10k(v): return format_unit(v, "ë§Œì›")
    def krw_10k_per_pyeong(v): return format_unit(v, "ë§Œì›/í‰")

    # --- 1. ì¢…í•© í†µê³„ (Overall Statistics) ---
    total_count = len(df)
    total_value = df['ê±°ë˜ê¸ˆì•¡_num'].sum()
    property_type_col = get_col_from_df(df, 'ì£¼ìš©ë„', 'ìœ í˜•', 'buildingUse')
    type_distribution = property_type_col.value_counts().to_dict() if property_type_col.notna().any() else {}

    overall_stats = {
        "totalTransactionCount": total_count,
        "totalTransactionValue": krw_10k(total_value),
        "transactionDistributionByPropertyType": type_distribution
    }

    # --- 2. ê°€ê²© ìˆ˜ì¤€ í†µê³„ (Price Level Statistics) ---
    price_stats_raw = df['ê±°ë˜ê¸ˆì•¡_num'].agg(['mean', 'median', 'max', 'min'])
    price_stats = {
        "overallAveragePrice": krw_10k(price_stats_raw['mean']),
        "overallMedianPrice": krw_10k(price_stats_raw['median']),
        "overallHighestPrice": krw_10k(price_stats_raw['max']),
        "overallLowestPrice": krw_10k(price_stats_raw['min'])
    }
    
    price_stats["representativeDeals"] = {
        "highestPriceDeal": clean_deal_for_display(df.loc[df['ê±°ë˜ê¸ˆì•¡_num'].idxmax()]),
        "lowestPriceDeal": clean_deal_for_display(df.loc[df['ê±°ë˜ê¸ˆì•¡_num'].idxmin()]),
        "dealClosestToAverage": clean_deal_for_display(df.loc[(df['ê±°ë˜ê¸ˆì•¡_num'] - price_stats_raw['mean']).abs().idxmin()]),
        "dealClosestToMedian": clean_deal_for_display(df.loc[(df['ê±°ë˜ê¸ˆì•¡_num'] - price_stats_raw['median']).abs().idxmin()])
    }

    if property_type_col.notna().any():
        price_by_type_raw = df.groupby(property_type_col)['ê±°ë˜ê¸ˆì•¡_num'].agg(['mean', 'median', 'max', 'min'])
        price_stats["priceStatisticsByPropertyType"] = {
            prop_type: {
                "averagePrice": krw_10k(stats['mean']),
                "medianPrice": krw_10k(stats['median']),
                "highestPrice": krw_10k(stats['max']),
                "lowestPrice": krw_10k(stats['min']),
            } for prop_type, stats in price_by_type_raw.to_dict('index').items()
        }

    # --- 3. ë‹¨ìœ„ ë©´ì ë‹¹ ê°€ê²© í†µê³„ (Price per Area Statistics) ---
    price_per_area_stats_raw = df['í‰ë‹¹ê°€_ë§Œì›'].agg(['mean', 'median'])
    price_per_area_stats = {
        "overallAveragePricePerPyeong": krw_10k_per_pyeong(price_per_area_stats_raw['mean']),
        "overallMedianPricePerPyeong": krw_10k_per_pyeong(price_per_area_stats_raw['median']),
    }
    if property_type_col.notna().any():
        price_per_area_by_type_raw = df.groupby(property_type_col)['í‰ë‹¹ê°€_ë§Œì›'].agg(['mean', 'median'])
        price_per_area_stats["pricePerPyeongStatisticsByPropertyType"] = {
            prop_type: {
                "averagePricePerPyeong": krw_10k_per_pyeong(stats['mean']),
                "medianPricePerPyeong": krw_10k_per_pyeong(stats['median']),
            } for prop_type, stats in price_per_area_by_type_raw.to_dict('index').items()
        }

    # --- 4. ì…ì§€ë³„ í†µê³„ (Location-based Statistics) ---
    location_col = get_col_from_df(df, 'ë²•ì •ë™', 'umdNm', 'dong')
    location_stats = {}
    if location_col.notna().any():
        location_summary_raw = df.groupby(location_col).agg(
            Count=('ê±°ë˜ê¸ˆì•¡_num', 'size'),
            Mean_Price=('ê±°ë˜ê¸ˆì•¡_num', 'mean'),
            Max_Price=('ê±°ë˜ê¸ˆì•¡_num', 'max'),
            Min_Price=('ê±°ë˜ê¸ˆì•¡_num', 'min'),
            Mean_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'mean'),
            Median_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'median')
        )
        
        for dong, stats in location_summary_raw.to_dict('index').items():
            location_stats[dong] = {
                "transactionCount": int(stats['Count']),
                "averagePrice": krw_10k(stats['Mean_Price']),
                "highestPrice": krw_10k(stats['Max_Price']),
                "lowestPrice": krw_10k(stats['Min_Price']),
                "averagePricePerPyeong": krw_10k_per_pyeong(stats['Mean_PPA']),
                "medianPricePerPyeong": krw_10k_per_pyeong(stats['Median_PPA']),
            }

    # --- 5. ê±´ë¬¼ íŠ¹ì„±ë³„ í†µê³„ (Building Characteristics Statistics) ---
    age_bins = [0, 6, 11, 21, np.inf]
    age_labels = ['5 years or newer', '6-10 years', '11-20 years', 'over 20 years']
    df['ê±´ë¬¼ì—°ë ¹ëŒ€'] = pd.cut(df['ê±´ë¬¼ì—°ë ¹'], bins=age_bins, labels=age_labels, right=False)
    age_stats = {}
    if not df['ê±´ë¬¼ì—°ë ¹ëŒ€'].isnull().all():
        age_summary_raw = df.groupby('ê±´ë¬¼ì—°ë ¹ëŒ€', observed=True).agg(
            Count=('ê±°ë˜ê¸ˆì•¡_num', 'size'),
            Mean_Price=('ê±°ë˜ê¸ˆì•¡_num', 'mean'),
            Mean_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'mean')
        )
        age_stats = {
            age_group: {
                "transactionCount": int(stats['Count']),
                "averagePrice": krw_10k(stats['Mean_Price']),
                "averagePricePerPyeong": krw_10k_per_pyeong(stats['Mean_PPA']),
            } for age_group, stats in age_summary_raw.to_dict('index').items()
        }

    area_bins = [0, 100, 300, 1000, np.inf]
    area_labels = ['small (<100mÂ²)', 'medium (100-300mÂ²)', 'large (300-1000mÂ²)', 'extra_large (>1000mÂ²)']
    df['ê±´ë¬¼ê·œëª¨'] = pd.cut(df['ì „ìš©ë©´ì _num'], bins=area_bins, labels=area_labels, right=False)
    scale_stats = {}
    if not df['ê±´ë¬¼ê·œëª¨'].isnull().all():
        scale_summary_raw = df.groupby('ê±´ë¬¼ê·œëª¨', observed=True).agg(
            Count=('ê±°ë˜ê¸ˆì•¡_num', 'size'),
            Mean_Price=('ê±°ë˜ê¸ˆì•¡_num', 'mean'),
            Mean_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'mean')
        )
        scale_stats = {
            scale_group: {
                "transactionCount": int(stats['Count']),
                "averagePrice": krw_10k(stats['Mean_Price']),
                "averagePricePerPyeong": krw_10k_per_pyeong(stats['Mean_PPA']),
            } for scale_group, stats in scale_summary_raw.to_dict('index').items()
        }
    
    building_stats = {
        "statisticsByBuildingAge": age_stats, 
        "statisticsByBuildingScale_exclusiveArea": scale_stats
    }

    return {
        "overallStatistics": overall_stats,
        "priceLevelStatistics": price_stats,
        "pricePerAreaStatistics": price_per_area_stats,
        "locationStatistics_byDong": location_stats,
        "buildingCharacteristicsStatistics": building_stats,
        "notes": "Price per pyeong and building scale are calculated based on the 'exclusive use area'. Data for 'land share' or 'road access conditions' is not provided by the API and is not included in this analysis."
    }

@mcp.tool(
    name="analyze_commercial_property_trade",
    description="""ìƒì—…ì—…ë¬´ìš©(ì˜¤í”¼ìŠ¤, ìƒê°€) ë¶€ë™ì‚° ë§¤ë§¤ ì‹¤ê±°ë˜ ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì›”ê°„ ë¦¬í¬íŠ¸ í˜•ì‹ì˜ í•µì‹¬ í†µê³„ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ ë„êµ¬ëŠ” `get_commercial_property_trade_data`ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ì‘ë™í•©ë‹ˆë‹¤.
ì¢…í•© í†µê³„, ê°€ê²© ìˆ˜ì¤€, í‰ë‹¹ê°€, ì…ì§€, ê±´ë¬¼ íŠ¹ì„±ë³„ ë“± ë‹¤ê°ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” í†µê³„ ì§€í‘œë“¤ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

Arguments:
- file_path (str, required): `get_commercial_property_trade_data` ë„êµ¬ë¡œ ìƒì„±ëœ `raw.data.json` ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ.

Returns:
- í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ìƒì„¸í•œ JSON ë¬¸ìì—´.
""",
    tags={"í†µê³„", "ë¶„ì„", "ë¦¬í¬íŠ¸", "ìƒì—…ì—…ë¬´ìš©", "ì‹¤ê±°ë˜ê°€"}
)
def analyze_commercial_property_trade(file_path: str, ctx: Optional[Any] = None) -> TextContent:
    """
    ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° ê±°ë˜ ë°ì´í„° XML íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í†µê³„ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    def call(context):
        try:
            p = Path(file_path)
            if not p.exists():
                return json.dumps({"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}, ensure_ascii=False)

            cache_path = get_summary_cache_path(p, property_type="commercial")

            # ìºì‹œ í™•ì¸ ë° ì¬ì‚¬ìš© ë¡œì§
            if cache_path.exists():
                source_mtime = p.stat().st_mtime
                cache_mtime = cache_path.stat().st_mtime
                if cache_mtime > source_mtime:
                    logger.info(f"âœ… ìœ íš¨í•œ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {cache_path}")
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return f.read()
            
            logger.info(f"ğŸ”„ ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ë˜ì–´ ìƒˆë¡œìš´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {file_path}")
            df = pd.read_json(p, lines=True)
            
            summary_data = analyze_commercial_property_data(df)
            
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=4, default=default_serializer)

            summary_data["summary_cached_path"] = str(cache_path)
            
            return json.dumps(summary_data, ensure_ascii=False, indent=4, default=default_serializer)

        except Exception as e:
            logger.error(f"ìƒì—…ì—…ë¬´ìš© ë¶€ë™ì‚° ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return json.dumps({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, ensure_ascii=False)
            
    result = with_context(ctx, "analyze_commercial_property_trade", call)
    return TextContent(type="text", text=result)

# --- ì•„íŒŒíŠ¸ ë§¤ë§¤ ë¶„ì„ ---

def analyze_apartment_trade_data(df: pd.DataFrame) -> Dict[str, Any]:
    """DataFrameì„ ë°›ì•„ ì•„íŒŒíŠ¸ ë§¤ë§¤ í†µê³„ë¥¼ ë¶„ì„í•˜ê³  ì˜ë¬¸ keyì™€ ë‹¨ìœ„ê°€ í¬í•¨ëœ ê°’ìœ¼ë¡œ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty:
        return {"error": "No data to analyze."}

    # --- ë°ì´í„° ì „ì²˜ë¦¬ ---
    df['ê±°ë˜ê¸ˆì•¡_num'] = to_numeric(get_col_from_df(df, 'ê±°ë˜ê¸ˆì•¡', 'dealAmount'))
    df['ì „ìš©ë©´ì _num'] = to_numeric(get_col_from_df(df, 'ì „ìš©ë©´ì ', 'area', 'excluUseAr'))
    df['ê±´ì¶•ë…„ë„_num'] = to_numeric(get_col_from_df(df, 'ê±´ì¶•ë…„ë„', 'buildYear'))
    df['ê³„ì•½ë…„ì›”_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ë…„ì›”'))
    df['ê³„ì•½ì¼_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ì¼'))

    df.dropna(subset=['ê±°ë˜ê¸ˆì•¡_num', 'ì „ìš©ë©´ì _num'], inplace=True)
    df = df[df['ì „ìš©ë©´ì _num'] > 0].copy()
    if df.empty:
        return {"error": "No valid transaction data after cleaning."}

    df['í‰ë‹¹ê°€_ë§Œì›'] = (df['ê±°ë˜ê¸ˆì•¡_num'] / df['ì „ìš©ë©´ì _num']) * 3.305785
    current_year = datetime.now().year
    df['ê±´ë¬¼ì—°ë ¹'] = current_year - df['ê±´ì¶•ë…„ë„_num']

    def krw_10k(v): return format_unit(v, "ë§Œì›")
    def krw_10k_per_pyeong(v): return format_unit(v, "ë§Œì›/í‰")

    # --- 1. ì¢…í•© í†µê³„ ---
    total_count = len(df)
    total_value = df['ê±°ë˜ê¸ˆì•¡_num'].sum()
    overall_stats = {
        "totalTransactionCount": total_count,
        "totalTransactionValue": krw_10k(total_value),
    }

    # --- 2. ê°€ê²© ìˆ˜ì¤€ í†µê³„ ---
    price_stats_raw = df['ê±°ë˜ê¸ˆì•¡_num'].agg(['mean', 'median', 'max', 'min'])
    price_stats = {
        "overallAveragePrice": krw_10k(price_stats_raw['mean']),
        "overallMedianPrice": krw_10k(price_stats_raw['median']),
        "overallHighestPrice": krw_10k(price_stats_raw['max']),
        "overallLowestPrice": krw_10k(price_stats_raw['min']),
        "representativeDeals": {
            "highestPriceDeal": clean_deal_for_display(df.loc[df['ê±°ë˜ê¸ˆì•¡_num'].idxmax()]),
            "lowestPriceDeal": clean_deal_for_display(df.loc[df['ê±°ë˜ê¸ˆì•¡_num'].idxmin()]),
            "dealClosestToAverage": clean_deal_for_display(df.loc[(df['ê±°ë˜ê¸ˆì•¡_num'] - price_stats_raw['mean']).abs().idxmin()]),
            "dealClosestToMedian": clean_deal_for_display(df.loc[(df['ê±°ë˜ê¸ˆì•¡_num'] - price_stats_raw['median']).abs().idxmin()])
        }
    }

    # --- 3. ë‹¨ìœ„ ë©´ì ë‹¹ ê°€ê²© í†µê³„ ---
    price_per_area_stats = {
        "overallAveragePricePerPyeong": krw_10k_per_pyeong(df['í‰ë‹¹ê°€_ë§Œì›'].mean()),
        "overallMedianPricePerPyeong": krw_10k_per_pyeong(df['í‰ë‹¹ê°€_ë§Œì›'].median()),
    }

    # --- 4. ë‹¨ì§€ë³„/ì…ì§€ë³„ í†µê³„ ---
    complex_col = get_col_from_df(df, 'ì•„íŒŒíŠ¸', 'ë‹¨ì§€ëª…', 'aptName')
    location_col = get_col_from_df(df, 'ë²•ì •ë™', 'umdNm', 'dong')
    
    def get_grouped_stats(group_col):
        stats = {}
        if group_col.notna().any():
            summary_raw = df.groupby(group_col).agg(
                Count=('ê±°ë˜ê¸ˆì•¡_num', 'size'),
                Mean_Price=('ê±°ë˜ê¸ˆì•¡_num', 'mean'),
                Median_Price=('ê±°ë˜ê¸ˆì•¡_num', 'median'),
                Mean_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'mean'),
                Median_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'median')
            )
            for name, data in summary_raw.to_dict('index').items():
                stats[name] = {
                    "transactionCount": int(data['Count']),
                    "averagePrice": krw_10k(data['Mean_Price']),
                    "medianPrice": krw_10k(data['Median_Price']),
                    "averagePricePerPyeong": krw_10k_per_pyeong(data['Mean_PPA']),
                    "medianPricePerPyeong": krw_10k_per_pyeong(data['Median_PPA']),
                }
        return stats

    complex_stats = get_grouped_stats(complex_col)
    location_stats = get_grouped_stats(location_col)

    return {
        "overallStatistics": overall_stats,
        "priceLevelStatistics": price_stats,
        "pricePerAreaStatistics": price_per_area_stats,
        "statisticsByApartmentComplex": complex_stats,
        "statisticsByDong": location_stats,
        "notes": "PPA (Price Per Pyeong) is calculated based on the 'exclusive use area'."
    }

@mcp.tool(
    name="analyze_apartment_trade",
    description="""ì•„íŒŒíŠ¸ ë§¤ë§¤ ì‹¤ê±°ë˜ ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì›”ê°„ ë¦¬í¬íŠ¸ í˜•ì‹ì˜ í•µì‹¬ í†µê³„ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ ë„êµ¬ëŠ” `get_apt_trade_data`ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ì‘ë™í•©ë‹ˆë‹¤.
ì¢…í•© í†µê³„, ê°€ê²© ìˆ˜ì¤€, í‰ë‹¹ê°€, ë‹¨ì§€ë³„, ë™ë³„ ë“± ë‹¤ê°ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” í†µê³„ ì§€í‘œë“¤ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

Arguments:
- file_path (str, required): `get_apt_trade_data` ë„êµ¬ë¡œ ìƒì„±ëœ `raw.data.json` ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ.

Returns:
- í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ìƒì„¸í•œ JSON ë¬¸ìì—´.
""",
    tags={"ì•„íŒŒíŠ¸", "í†µê³„", "ë¶„ì„", "ë¦¬í¬íŠ¸", "ë§¤ë§¤", "ì‹¤ê±°ë˜ê°€"}
)
def analyze_apartment_trade(file_path: str, ctx: Optional[Any] = None) -> TextContent:
    """
    ì•„íŒŒíŠ¸ ë§¤ë§¤ ê±°ë˜ ë°ì´í„° XML íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í†µê³„ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    def call(context):
        try:
            p = Path(file_path)
            if not p.exists():
                return json.dumps({"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}, ensure_ascii=False)

            cache_path = get_summary_cache_path(p, property_type="apartment", trade_type="trade")

            if cache_path.exists():
                if cache_path.stat().st_mtime > p.stat().st_mtime:
                    logger.info(f"âœ… ìœ íš¨í•œ ì•„íŒŒíŠ¸ ë§¤ë§¤ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {cache_path}")
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return f.read()
            
            logger.info(f"ğŸ”„ ìƒˆë¡œìš´ ì•„íŒŒíŠ¸ ë§¤ë§¤ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {file_path}")
            df = pd.read_json(p, lines=True)
            
            summary_data = analyze_apartment_trade_data(df)
            
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=4, default=default_serializer)

            summary_data["summary_cached_path"] = str(cache_path)
            return json.dumps(summary_data, ensure_ascii=False, indent=4, default=default_serializer)

        except Exception as e:
            logger.error(f"ì•„íŒŒíŠ¸ ë§¤ë§¤ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return json.dumps({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, ensure_ascii=False)
            
    result = with_context(ctx, "analyze_apartment_trade", call)
    return TextContent(type="text", text=result)

# --- ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ë¶„ì„ ---

def analyze_apartment_rent_data(df: pd.DataFrame) -> Dict[str, Any]:
    """DataFrameì„ ë°›ì•„ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ í†µê³„ë¥¼ ë¶„ì„í•˜ê³  ì „ì„¸/ì›”ì„¸ë¥¼ êµ¬ë¶„í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty:
        return {"error": "No data to analyze."}

    # --- ë°ì´í„° ì „ì²˜ë¦¬ ---
    df['ë³´ì¦ê¸ˆ_num'] = to_numeric(get_col_from_df(df, 'ë³´ì¦ê¸ˆì•¡', 'ë³´ì¦ê¸ˆ', 'deposit', 'depositNum'))
    df['ì›”ì„¸_num'] = to_numeric(get_col_from_df(df, 'ì›”ì„¸ì•¡', 'ì›”ì„¸', 'monthlyRent', 'rentFeeNum'))
    df['ì „ìš©ë©´ì _num'] = to_numeric(get_col_from_df(df, 'ì „ìš©ë©´ì ', 'area', 'excluUseAr', 'areaNum'))
    df['ê±´ì¶•ë…„ë„_num'] = to_numeric(get_col_from_df(df, 'ê±´ì¶•ë…„ë„', 'buildYear'))
    df['ê³„ì•½ë…„ì›”_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ë…„ì›”'))
    df['ê³„ì•½ì¼_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ì¼'))

    df.dropna(subset=['ë³´ì¦ê¸ˆ_num', 'ì›”ì„¸_num', 'ì „ìš©ë©´ì _num'], inplace=True)
    df = df[df['ì „ìš©ë©´ì _num'] > 0].copy()
    if df.empty:
        return {"error": "No valid transaction data after cleaning."}

    df_jeonse = df[df['ì›”ì„¸_num'] == 0].copy()
    df_wolse = df[df['ì›”ì„¸_num'] > 0].copy()

    def krw_10k(v): return format_unit(v, "ë§Œì›")
    
    def analyze_rent_type(df_rent_type, rent_type_name):
        if df_rent_type.empty:
            return { "totalTransactionCount": 0 }

        stats = { "totalTransactionCount": len(df_rent_type) }
        
        price_stats_raw = df_rent_type['ë³´ì¦ê¸ˆ_num'].agg(['mean', 'median', 'max', 'min'])
        stats['depositPriceStatistics'] = {
            "averageDeposit": krw_10k(price_stats_raw['mean']),
            "medianDeposit": krw_10k(price_stats_raw['median']),
            "highestDeposit": krw_10k(price_stats_raw['max']),
            "lowestDeposit": krw_10k(price_stats_raw['min']),
            "representativeDeals": {
                "highestDepositDeal": clean_deal_for_display(df_rent_type.loc[df_rent_type['ë³´ì¦ê¸ˆ_num'].idxmax()]),
                "lowestDepositDeal": clean_deal_for_display(df_rent_type.loc[df_rent_type['ë³´ì¦ê¸ˆ_num'].idxmin()]),
            }
        }
        if rent_type_name == 'wolse': # ì›”ì„¸ í†µê³„ ì¶”ê°€
            wolse_stats_raw = df_rent_type['ì›”ì„¸_num'].agg(['mean', 'median', 'max', 'min'])
            stats['monthlyRentStatistics'] = {
                "averageMonthlyRent": krw_10k(wolse_stats_raw['mean']),
                "medianMonthlyRent": krw_10k(wolse_stats_raw['median']),
            }

        complex_col = get_col_from_df(df_rent_type, 'ì•„íŒŒíŠ¸', 'ë‹¨ì§€ëª…', 'aptName')
        if complex_col.notna().any():
            stats['statisticsByApartmentComplex'] = df_rent_type.groupby(complex_col).agg(
                transactionCount=('ë³´ì¦ê¸ˆ_num', 'size'),
                averageDeposit=('ë³´ì¦ê¸ˆ_num', 'mean')
            ).apply(lambda x: x.astype(int) if x.name == 'transactionCount' else krw_10k(x)).to_dict('index')

        return stats

    jeonse_analysis = analyze_rent_type(df_jeonse, 'jeonse')
    wolse_analysis = analyze_rent_type(df_wolse, 'wolse')
    
    return {
        "transactionTypeDistribution": {
            "jeonse_count": len(df_jeonse),
            "wolse_count": len(df_wolse),
        },
        "jeonseAnalysis": jeonse_analysis,
        "wolseAnalysis": wolse_analysis,
        "notes": "Statistics are separated by transaction type (Jeonse vs. Wolse)."
    }

@mcp.tool(
    name="analyze_apartment_rent",
    description="""ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì›”ê°„ ë¦¬í¬íŠ¸ í˜•ì‹ì˜ í•µì‹¬ í†µê³„ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ ë„êµ¬ëŠ” `get_apt_rent_data`ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ì‘ë™í•˜ë©°, 'ì „ì„¸'ì™€ 'ì›”ì„¸'ë¥¼ ìë™ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ê°ê°ì— ëŒ€í•œ ìƒì„¸ í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” í†µê³„ ì§€í‘œë“¤ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

- **ê±°ë˜ ìœ í˜• ë¶„í¬**: ì „ì²´ ê±°ë˜ ì¤‘ ì „ì„¸ì™€ ì›”ì„¸ì˜ ë¹„ì¤‘ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- **ì „ì„¸ ë¶„ì„**: ë³´ì¦ê¸ˆì— ëŒ€í•œ í‰ê· /ì¤‘ìœ„/ìµœê³ /ìµœì € ê°€ê²© ë° ì£¼ìš” ê±°ë˜ ì‚¬ë¡€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¨ì§€ë³„ í†µê³„ë„ í¬í•¨ë©ë‹ˆë‹¤.
- **ì›”ì„¸ ë¶„ì„**: ë³´ì¦ê¸ˆ ë° ì›”ì„¸ ê°ê°ì— ëŒ€í•œ í‰ê· /ì¤‘ìœ„ ê°€ê²© í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¨ì§€ë³„ í†µê³„ë„ í¬í•¨ë©ë‹ˆë‹¤.

Arguments:
- file_path (str, required): `get_apt_rent_data` ë„êµ¬ë¡œ ìƒì„±ëœ `raw.data.json` ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ.

Returns:
- ì „ì„¸ì™€ ì›”ì„¸ë¡œ êµ¬ë¶„ëœ í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ìƒì„¸í•œ JSON ë¬¸ìì—´.
""",
    tags={"ì•„íŒŒíŠ¸", "í†µê³„", "ë¶„ì„", "ë¦¬í¬íŠ¸", "ì „ì„¸", "ì›”ì„¸", "ì „ì›”ì„¸", "ì‹¤ê±°ë˜ê°€"}
)
def analyze_apartment_rent(file_path: str, ctx: Optional[Any] = None) -> TextContent:
    """
    ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ê±°ë˜ ë°ì´í„° XML íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í†µê³„ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    def call(context):
        try:
            p = Path(file_path)
            if not p.exists():
                return json.dumps({"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}, ensure_ascii=False)

            cache_path = get_summary_cache_path(p, property_type="apartment", trade_type="rent")

            if cache_path.exists():
                if cache_path.stat().st_mtime > p.stat().st_mtime:
                    logger.info(f"âœ… ìœ íš¨í•œ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {cache_path}")
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return f.read()
            
            logger.info(f"ğŸ”„ ìƒˆë¡œìš´ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {file_path}")
            df = pd.read_json(p, lines=True)
            
            summary_data = analyze_apartment_rent_data(df)
            
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=4, default=default_serializer)

            summary_data["summary_cached_path"] = str(cache_path)
            return json.dumps(summary_data, ensure_ascii=False, indent=4, default=default_serializer)

        except Exception as e:
            logger.error(f"ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return json.dumps({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, ensure_ascii=False)
            
    result = with_context(ctx, "analyze_apartment_rent", call)
    return TextContent(type="text", text=result)

# --- ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤ ë¶„ì„ ---

def analyze_officetel_trade_data(df: pd.DataFrame) -> Dict[str, Any]:
    """DataFrameì„ ë°›ì•„ ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤ í†µê³„ë¥¼ ë¶„ì„í•˜ê³  ì˜ë¬¸ keyì™€ ë‹¨ìœ„ê°€ í¬í•¨ëœ ê°’ìœ¼ë¡œ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty:
        return {"error": "No data to analyze."}

    # --- ë°ì´í„° ì „ì²˜ë¦¬ ---
    df['ê±°ë˜ê¸ˆì•¡_num'] = to_numeric(get_col_from_df(df, 'ê±°ë˜ê¸ˆì•¡', 'dealAmount', 'dealAmountNum'))
    df['ì „ìš©ë©´ì _num'] = to_numeric(get_col_from_df(df, 'ì „ìš©ë©´ì ', 'area', 'excluUseAr', 'areaNum'))
    df['ê±´ì¶•ë…„ë„_num'] = to_numeric(get_col_from_df(df, 'ê±´ì¶•ë…„ë„', 'buildYear', 'buildYearNum'))
    df['ê³„ì•½ë…„ì›”_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ë…„ì›”'))
    df['ê³„ì•½ì¼_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ì¼'))

    df.dropna(subset=['ê±°ë˜ê¸ˆì•¡_num', 'ì „ìš©ë©´ì _num'], inplace=True)
    df = df[df['ì „ìš©ë©´ì _num'] > 0].copy()
    if df.empty:
        return {"error": "No valid transaction data after cleaning."}

    df['í‰ë‹¹ê°€_ë§Œì›'] = (df['ê±°ë˜ê¸ˆì•¡_num'] / df['ì „ìš©ë©´ì _num']) * 3.305785
    current_year = datetime.now().year
    df['ê±´ë¬¼ì—°ë ¹'] = current_year - df['ê±´ì¶•ë…„ë„_num']

    def krw_10k(v): return format_unit(v, "ë§Œì›")
    def krw_10k_per_pyeong(v): return format_unit(v, "ë§Œì›/í‰")

    # --- 1. ì¢…í•© í†µê³„ ---
    total_count = len(df)
    total_value = df['ê±°ë˜ê¸ˆì•¡_num'].sum()
    overall_stats = {
        "totalTransactionCount": total_count,
        "totalTransactionValue": krw_10k(total_value),
    }

    # --- 2. ê°€ê²© ìˆ˜ì¤€ í†µê³„ ---
    price_stats_raw = df['ê±°ë˜ê¸ˆì•¡_num'].agg(['mean', 'median', 'max', 'min'])
    price_stats = {
        "overallAveragePrice": krw_10k(price_stats_raw['mean']),
        "overallMedianPrice": krw_10k(price_stats_raw['median']),
        "overallHighestPrice": krw_10k(price_stats_raw['max']),
        "overallLowestPrice": krw_10k(price_stats_raw['min']),
        "representativeDeals": {
            "highestPriceDeal": clean_deal_for_display(df.loc[df['ê±°ë˜ê¸ˆì•¡_num'].idxmax()]),
            "lowestPriceDeal": clean_deal_for_display(df.loc[df['ê±°ë˜ê¸ˆì•¡_num'].idxmin()]),
            "dealClosestToAverage": clean_deal_for_display(df.loc[(df['ê±°ë˜ê¸ˆì•¡_num'] - price_stats_raw['mean']).abs().idxmin()]),
            "dealClosestToMedian": clean_deal_for_display(df.loc[(df['ê±°ë˜ê¸ˆì•¡_num'] - price_stats_raw['median']).abs().idxmin()])
        }
    }

    # --- 3. ë‹¨ìœ„ ë©´ì ë‹¹ ê°€ê²© í†µê³„ ---
    price_per_area_stats = {
        "overallAveragePricePerPyeong": krw_10k_per_pyeong(df['í‰ë‹¹ê°€_ë§Œì›'].mean()),
        "overallMedianPricePerPyeong": krw_10k_per_pyeong(df['í‰ë‹¹ê°€_ë§Œì›'].median()),
    }

    # --- 4. ë‹¨ì§€ë³„/ì…ì§€ë³„ í†µê³„ ---
    complex_col = get_col_from_df(df, 'ì˜¤í”¼ìŠ¤í…”', 'ì˜¤í”¼ìŠ¤í…”ëª…', 'officetelName')
    location_col = get_col_from_df(df, 'ë²•ì •ë™', 'umdNm', 'dong')
    def get_grouped_stats(group_col):
        stats = {}
        if group_col.notna().any():
            summary_raw = df.groupby(group_col).agg(
                Count=('ê±°ë˜ê¸ˆì•¡_num', 'size'),
                Mean_Price=('ê±°ë˜ê¸ˆì•¡_num', 'mean'),
                Median_Price=('ê±°ë˜ê¸ˆì•¡_num', 'median'),
                Mean_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'mean'),
                Median_PPA=('í‰ë‹¹ê°€_ë§Œì›', 'median')
            )
            for name, data in summary_raw.to_dict('index').items():
                stats[name] = {
                    "transactionCount": int(data['Count']),
                    "averagePrice": krw_10k(data['Mean_Price']),
                    "medianPrice": krw_10k(data['Median_Price']),
                    "averagePricePerPyeong": krw_10k_per_pyeong(data['Mean_PPA']),
                    "medianPricePerPyeong": krw_10k_per_pyeong(data['Median_PPA']),
                }
        return stats
    complex_stats = get_grouped_stats(complex_col)
    location_stats = get_grouped_stats(location_col)
    return {
        "overallStatistics": overall_stats,
        "priceLevelStatistics": price_stats,
        "pricePerAreaStatistics": price_per_area_stats,
        "statisticsByOfficetelComplex": complex_stats,
        "statisticsByDong": location_stats,
        "notes": "PPA (Price Per Pyeong) is calculated based on the 'exclusive use area'."
    }

@mcp.tool(
    name="analyze_officetel_trade",
    description="""ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤ ì‹¤ê±°ë˜ ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì›”ê°„ ë¦¬í¬íŠ¸ í˜•ì‹ì˜ í•µì‹¬ í†µê³„ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\nì´ ë„êµ¬ëŠ” `get_officetel_trade_data`ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ì‘ë™í•©ë‹ˆë‹¤.\nì¢…í•© í†µê³„, ê°€ê²© ìˆ˜ì¤€, í‰ë‹¹ê°€, ë‹¨ì§€ë³„, ë™ë³„ ë“± ë‹¤ê°ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\në¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” í†µê³„ ì§€í‘œë“¤ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n\nArguments:\n- file_path (str, required): `get_officetel_trade_data` ë„êµ¬ë¡œ ìƒì„±ëœ `raw.data.json` ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ.\n\nReturns:\n- í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ìƒì„¸í•œ JSON ë¬¸ìì—´.""",
    tags={"ì˜¤í”¼ìŠ¤í…”", "í†µê³„", "ë¶„ì„", "ë¦¬í¬íŠ¸", "ë§¤ë§¤", "ì‹¤ê±°ë˜ê°€"}
)
def analyze_officetel_trade(file_path: str, ctx: Optional[Any] = None) -> TextContent:
    def call(context):
        try:
            p = Path(file_path)
            if not p.exists():
                return json.dumps({"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}, ensure_ascii=False)
            cache_path = get_summary_cache_path(p, property_type="officetel", trade_type="trade")
            if cache_path.exists():
                if cache_path.stat().st_mtime > p.stat().st_mtime:
                    logger.info(f"âœ… ìœ íš¨í•œ ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {cache_path}")
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return f.read()
            logger.info(f"ğŸ”„ ìƒˆë¡œìš´ ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {file_path}")
            df = pd.read_json(p, lines=True)
            summary_data = analyze_officetel_trade_data(df)
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=4, default=default_serializer)
            summary_data["summary_cached_path"] = str(cache_path)
            return json.dumps(summary_data, ensure_ascii=False, indent=4, default=default_serializer)
        except Exception as e:
            logger.error(f"ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return json.dumps({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, ensure_ascii=False)
    result = with_context(ctx, "analyze_officetel_trade", call)
    return TextContent(type="text", text=result)

# --- ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ë¶„ì„ ---
def analyze_officetel_rent_data(df: pd.DataFrame) -> Dict[str, Any]:
    """DataFrameì„ ë°›ì•„ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ í†µê³„ë¥¼ ë¶„ì„í•˜ê³  ì „ì„¸/ì›”ì„¸ë¥¼ êµ¬ë¶„í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty:
        return {"error": "No data to analyze."}
    df['ë³´ì¦ê¸ˆ_num'] = to_numeric(get_col_from_df(df, 'ë³´ì¦ê¸ˆì•¡', 'ë³´ì¦ê¸ˆ', 'deposit', 'depositNum'))
    df['ì›”ì„¸_num'] = to_numeric(get_col_from_df(df, 'ì›”ì„¸ê¸ˆì•¡', 'ì›”ì„¸', 'monthlyRent', 'rentFeeNum'))
    df['ì „ìš©ë©´ì _num'] = to_numeric(get_col_from_df(df, 'ì „ìš©ë©´ì ', 'area', 'excluUseAr', 'areaNum'))
    df['ê±´ì¶•ë…„ë„_num'] = to_numeric(get_col_from_df(df, 'ê±´ì¶•ë…„ë„', 'buildYear', 'buildYearNum'))
    df['ê³„ì•½ë…„ì›”_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ë…„ì›”'))
    df['ê³„ì•½ì¼_num'] = to_numeric(get_col_from_df(df, 'ê³„ì•½ì¼'))
    df.dropna(subset=['ë³´ì¦ê¸ˆ_num', 'ì›”ì„¸_num', 'ì „ìš©ë©´ì _num'], inplace=True)
    df = df[df['ì „ìš©ë©´ì _num'] > 0].copy()
    if df.empty:
        return {"error": "No valid transaction data after cleaning."}
    df_jeonse = df[df['ì›”ì„¸_num'] == 0].copy()
    df_wolse = df[df['ì›”ì„¸_num'] > 0].copy()
    def krw_10k(v): return format_unit(v, "ë§Œì›")
    def analyze_rent_type(df_rent_type, rent_type_name):
        if df_rent_type.empty:
            return { "totalTransactionCount": 0 }
        stats = { "totalTransactionCount": len(df_rent_type) }
        price_stats_raw = df_rent_type['ë³´ì¦ê¸ˆ_num'].agg(['mean', 'median', 'max', 'min'])
        stats['depositPriceStatistics'] = {
            "averageDeposit": krw_10k(price_stats_raw['mean']),
            "medianDeposit": krw_10k(price_stats_raw['median']),
            "highestDeposit": krw_10k(price_stats_raw['max']),
            "lowestDeposit": krw_10k(price_stats_raw['min']),
            "representativeDeals": {
                "highestDepositDeal": clean_deal_for_display(df_rent_type.loc[df_rent_type['ë³´ì¦ê¸ˆ_num'].idxmax()]),
                "lowestDepositDeal": clean_deal_for_display(df_rent_type.loc[df_rent_type['ë³´ì¦ê¸ˆ_num'].idxmin()]),
            }
        }
        if rent_type_name == 'wolse':
            wolse_stats_raw = df_rent_type['ì›”ì„¸_num'].agg(['mean', 'median', 'max', 'min'])
            stats['monthlyRentStatistics'] = {
                "averageMonthlyRent": krw_10k(wolse_stats_raw['mean']),
                "medianMonthlyRent": krw_10k(wolse_stats_raw['median']),
            }
        complex_col = get_col_from_df(df_rent_type, 'ì˜¤í”¼ìŠ¤í…”', 'ì˜¤í”¼ìŠ¤í…”ëª…', 'officetelName')
        if complex_col.notna().any():
            stats['statisticsByOfficetelComplex'] = df_rent_type.groupby(complex_col).agg(
                transactionCount=('ë³´ì¦ê¸ˆ_num', 'size'),
                averageDeposit=('ë³´ì¦ê¸ˆ_num', 'mean')
            ).apply(lambda x: x.astype(int) if x.name == 'transactionCount' else krw_10k(x)).to_dict('index')
        return stats
    jeonse_analysis = analyze_rent_type(df_jeonse, 'jeonse')
    wolse_analysis = analyze_rent_type(df_wolse, 'wolse')
    return {
        "transactionTypeDistribution": {
            "jeonse_count": len(df_jeonse),
            "wolse_count": len(df_wolse),
        },
        "jeonseAnalysis": jeonse_analysis,
        "wolseAnalysis": wolse_analysis,
        "notes": "Statistics are separated by transaction type (Jeonse vs. Wolse)."
    }

@mcp.tool(
    name="analyze_officetel_rent",
    description="""ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ì‹¤ê±°ë˜ ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì›”ê°„ ë¦¬í¬íŠ¸ í˜•ì‹ì˜ í•µì‹¬ í†µê³„ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\nì´ ë„êµ¬ëŠ” `get_officetel_rent_data`ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ ì‘ë™í•˜ë©°, 'ì „ì„¸'ì™€ 'ì›”ì„¸'ë¥¼ ìë™ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ê°ê°ì— ëŒ€í•œ ìƒì„¸ í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\në¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” í†µê³„ ì§€í‘œë“¤ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n\n- **ê±°ë˜ ìœ í˜• ë¶„í¬**: ì „ì²´ ê±°ë˜ ì¤‘ ì „ì„¸ì™€ ì›”ì„¸ì˜ ë¹„ì¤‘ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n- **ì „ì„¸ ë¶„ì„**: ë³´ì¦ê¸ˆì— ëŒ€í•œ í‰ê· /ì¤‘ìœ„/ìµœê³ /ìµœì € ê°€ê²© ë° ì£¼ìš” ê±°ë˜ ì‚¬ë¡€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¨ì§€ë³„ í†µê³„ë„ í¬í•¨ë©ë‹ˆë‹¤.\n- **ì›”ì„¸ ë¶„ì„**: ë³´ì¦ê¸ˆ ë° ì›”ì„¸ ê°ê°ì— ëŒ€í•œ í‰ê· /ì¤‘ìœ„ ê°€ê²© í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¨ì§€ë³„ í†µê³„ë„ í¬í•¨ë©ë‹ˆë‹¤.\n\nArguments:\n- file_path (str, required): `get_officetel_rent_data` ë„êµ¬ë¡œ ìƒì„±ëœ `raw.data.json` ë°ì´í„° íŒŒì¼ì˜ ê²½ë¡œ.\n\nReturns:\n- ì „ì„¸ì™€ ì›”ì„¸ë¡œ êµ¬ë¶„ëœ í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ ìƒì„¸í•œ JSON ë¬¸ìì—´.""",
    tags={"ì˜¤í”¼ìŠ¤í…”", "í†µê³„", "ë¶„ì„", "ë¦¬í¬íŠ¸", "ì „ì„¸", "ì›”ì„¸", "ì „ì›”ì„¸", "ì‹¤ê±°ë˜ê°€"}
)
def analyze_officetel_rent(file_path: str, ctx: Optional[Any] = None) -> TextContent:
    def call(context):
        try:
            p = Path(file_path)
            if not p.exists():
                return json.dumps({"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"}, ensure_ascii=False)
            cache_path = get_summary_cache_path(p, property_type="officetel", trade_type="rent")
            if cache_path.exists():
                if cache_path.stat().st_mtime > p.stat().st_mtime:
                    logger.info(f"âœ… ìœ íš¨í•œ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {cache_path}")
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return f.read()
            logger.info(f"ğŸ”„ ìƒˆë¡œìš´ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {file_path}")
            df = pd.read_json(p, lines=True)
            summary_data = analyze_officetel_rent_data(df)
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=4, default=default_serializer)
            summary_data["summary_cached_path"] = str(cache_path)
            return json.dumps(summary_data, ensure_ascii=False, indent=4, default=default_serializer)
        except Exception as e:
            logger.error(f"ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return json.dumps({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}, ensure_ascii=False)
    result = with_context(ctx, "analyze_officetel_rent", call)
    return TextContent(type="text", text=result) 